---
project:
  title: "Lab 6: Machine Learning in Hydrology"
  output-dir:  docs
  type: website
  
format:
  html:
    self-contained: true
---

# Lab Set Up

```{r}
library(tidyverse)
library(tidymodels)
library(powerjoin)
library(glue)
library(vip)
library(baguette)
library(ggthemes)

```

```{r}
root  <- 'https://gdex.ucar.edu/dataset/camels/file'
download.file('https://gdex.ucar.edu/dataset/camels/file/camels_attributes_v2.0.pdf', 
              'data/camels_attributes_v2.0.pdf', mode = "wb")

types <- c("clim", "geol", "soil", "topo", "vege", "hydro")

remote_files  <- glue('{root}/camels_{types}.txt')

local_files   <- glue('data/camels_{types}.txt')

walk2(remote_files, local_files, download.file, quiet = TRUE)

camels <- map(local_files, read_delim, show_col_types = FALSE)

camels <- power_full_join(camels ,by = 'gauge_id')

```

# Question 1

```{r}
install.packages("ggthemes")
library(ggplot2)
library(ggthemes)
ggplot(data = camels, aes(x = gauge_lon, y = gauge_lat)) +
  borders("state", colour = "gray50") +
  geom_point(aes(color = q_mean)) +
  scale_color_gradient(low = "pink", high = "dodgerblue") +
  ggthemes::theme_map()
```

```{r}
# zero_q_freq represents the amount of times within a period of time, where the stream flow is zero
```

# Question 2

```{r}
# Model Preparation
camels |> 
  select(aridity, p_mean, q_mean) |> 
  drop_na() |> 
  cor()
```

```{r}
# Visual EDA
ggplot(camels, aes(x = aridity, y = p_mean)) +
  geom_point(aes(color = q_mean)) +
  geom_smooth(method = "lm", color = "red", linetype = 2) +
  scale_color_viridis_c() +
  theme_linedraw() + 
  theme(legend.position = "bottom") + 
  labs(title = "Aridity vs Rainfall vs Runnoff", 
       x = "Aridity", 
       y = "Rainfall",
       color = "Mean Flow")
```

```{r}
ggplot(camels, aes(x = aridity, y = p_mean)) +
  geom_point(aes(color = q_mean)) +
  geom_smooth(method = "lm") +
  scale_color_viridis_c() +
  scale_x_log10() + 
  scale_y_log10() +
  theme_linedraw() +
  theme(legend.position = "bottom") + 
  labs(title = "Aridity vs Rainfall vs Runnoff", 
       x = "Aridity", 
       y = "Rainfall",
       color = "Mean Flow")
```

```{r}
ggplot(camels, aes(x = aridity, y = p_mean)) +
  geom_point(aes(color = q_mean)) +
  geom_smooth(method = "lm") +
  scale_color_viridis_c(trans = "log") +
  scale_x_log10() + 
  scale_y_log10() +
  theme_linedraw() +
  theme(legend.position = "bottom",
        legend.key.width = unit(2.5, "cm"),
        legend.key.height = unit(.5, "cm")) + 
  labs(title = "Aridity vs Rainfall vs Runnoff", 
       x = "Aridity", 
       y = "Rainfall",
       color = "Mean Flow") 
```

```{r}
# Model Building - Splitting the data 
set.seed(123)

camels <- camels |> 
  mutate(logQmean = log(q_mean))

camels_split <- initial_split(camels, prop = 0.8)
camels_train <- training(camels_split)
camels_test  <- testing(camels_split)

camels_cv <- vfold_cv(camels_train, v = 10)
```

```{r}
# Model Building - preprocessor: rrecipe 
rec <-  recipe(logQmean ~ aridity + p_mean, data = camels_train) %>%
  step_log(all_predictors()) %>%
  step_interact(terms = ~ aridity:p_mean) |> 
  step_naomit(all_predictors(), all_outcomes())
```

```{r}
# Model Building - Naive base lm approach
baked_data <- prep(rec, camels_train) |> 
  bake(new_data = NULL)

lm_base <- lm(logQmean ~ aridity * p_mean, data = baked_data)
summary(lm_base)
```

```{r}
summary(lm(logQmean ~ aridity + p_mean + aridity_x_p_mean, data = baked_data))
```

```{r}
# Model Building - correct version: prep -> bake -> predict 
test_data <-  bake(prep(rec), new_data = camels_test)
test_data$lm_pred <- predict(lm_base, newdata = test_data)
```

```{r}
# Model Evaluation: Statistical and visual 
metrics(test_data, truth = logQmean, estimate = lm_pred)
```

```{r}
ggplot(test_data, aes(x = logQmean, y = lm_pred, colour = aridity)) +
  scale_color_gradient2(low = "brown", mid = "orange", high = "darkgreen") +
  geom_point() +
  geom_abline(linetype = 2) +
  theme_linedraw() + 
  labs(title = "Linear Model: Observed vs Predicted",
       x = "Observed Log Mean Flow",
       y = "Predicted Log Mean Flow",
       color = "Aridity")
```

```{r}
# Using a workflow instead
lm_model <- linear_reg() %>%
  set_engine("lm") %>%
  set_mode("regression")

lm_wf <- workflow() %>%
  add_recipe(rec) %>%
  add_model(lm_model) %>%
  fit(data = camels_train) 

summary(extract_fit_engine(lm_wf))$coefficients
```

```{r}
summary(lm_base)$coefficients
```

```{r}
# Making Predictions 
lm_data <- augment(lm_wf, new_data = camels_test)
dim(lm_data)
```

```{r}
# Model Evaluation: statistical and visual 
metrics(lm_data, truth = logQmean, estimate = .pred)
```

```{r}
ggplot(lm_data, aes(x = logQmean, y = .pred, colour = aridity)) +
  scale_color_viridis_c() +
  geom_point() +
  geom_abline() +
  theme_linedraw()
```

```{r}
# Switch it up
library(baguette)
rf_model <- rand_forest() %>%
  set_engine("ranger", importance = "impurity") %>%
  set_mode("regression")

rf_wf <- workflow() %>%
  add_recipe(rec) %>%
  add_model(rf_model) %>%
  fit(data = camels_train) 
```

```{r}
# Predictions
rf_data <- augment(rf_wf, new_data = camels_test)
dim(rf_data)
```

```{r}
# Model Evaluation: Statistical and visual 
metrics(rf_data, truth = logQmean, estimate = .pred)
```

```{r}
ggplot(rf_data, aes(x = logQmean, y = .pred, colour = aridity)) +
  scale_color_viridis_c() +
  geom_point() +
  geom_abline() +
  theme_linedraw()
```

```{r}
# A workflow approach
wf <- workflow_set(list(rec), list(lm_model, rf_model)) %>%
  workflow_map('fit_resamples', resamples = camels_cv) 

autoplot(wf)
```

```{r}
rank_results(wf, rank_metric = "rsq", select_best = TRUE)
```

```{r}
# Make 2 maps of the sites, coloring the points by the aridty and p_mean column
library(ggplot2)
library(sf)
library(viridis) 
library(patchwork)

camels_sf <- st_as_sf(camels, coords = c("gauge_lon", "gauge_lat"), crs = 4326)

map_aridity <- ggplot(data = camels_sf) +
  geom_sf(aes(color = aridity), size = 2) + 
  scale_color_viridis(option = "C", name = "Aridity") +
  labs(title = "Sites Colored by Aridity", x = "Longitude", y = "Latitude") +
  theme_minimal()

map_p_mean <- ggplot(data = camels_sf) +
  geom_sf(aes(color = p_mean), size = 2) +
  scale_color_viridis(option = "D", name = "Mean Precipitation (mm)") +
  labs(title = "Sites Colored by Mean Precipitation", x = "Longitude", y = "Latitude") +
  theme_minimal()

combined_map <- map_aridity + map_p_mean + plot_layout(ncol = 1)

print(combined_map)

```

# Question 3

```{r}
library(tidymodels)
library(baguette)
library(xgboost)
library(ggplot2)

xgb_model <- boost_tree(trees = 1000, tree_depth = 6, learn_rate = 0.1) %>%
  set_engine("xgboost") %>%
  set_mode("regression")
nnet_model <- bag_mlp() %>%
  set_engine("nnet") %>%
  set_mode("regression")

wf <- workflow_set(
  preproc = list(rec),
  models = list(lm_model, rf_model, xgb_model, nnet_model)
) %>%
  workflow_map('fit_resamples', resamples = camels_cv)

autoplot(wf)
rank_results(wf, rank_metric = "rsq", select_best = TRUE)
```

```{r}
#I think the bag_mlp is the best model because it has the highest R^2 so it would explain the most variance in the data  
```

# Question 4: Build Your Own

#4a. Data Splitting

```{r}
set.seed(123)

data_split <- initial_split(camels, prop = 0.75, strata = logQmean)

train_data <- training(data_split)
test_data  <- testing(data_split)

camels_cv <- vfold_cv(train_data, v = 10, strata = logQmean)

```

#4b. Recipe

```{r}


#formula I would like to use to predict logQmean: logQmean ~ p_mean + pet_mean + elev_mean + area_gages2 + max_water_content + slope_mean. The log of Qmean will help reduce the impact of extreme values and create a better linear relationship. I chose these predictors because they all influence the stream flow

rec <- recipe(logQmean ~ p_mean + pet_mean + elev_mean + area_gages2 + max_water_content + slope_mean, 
              data = camels_train) %>%
  step_log(logQmean, base = 10) %>%
  step_normalize(all_numeric_predictors()) %>%
  step_naomit(all_predictors(), all_outcomes())

baked_data <- prep(rec, training = camels_train) %>%
  bake(new_data = NULL)

glimpse(baked_data)

```

#4c. Define 3 models

```{r}

##Random Forest Model
rf_model <- rand_forest(trees = 500) %>%
  set_engine("ranger") %>%
  set_mode("regression")

##XGBoost Model
xgb_model <- boost_tree(trees = 500, tree_depth = 6, learn_rate = 0.1) %>%
  set_engine("xgboost") %>%
  set_mode("regression")

##Decision Tree Regression
dt_model <- decision_tree(tree_depth = 6) %>%
  set_engine("rpart") %>%
  set_mode("regression")
```

#4d. Workflow set

```{r}

rf_workflow <- workflow() %>%
  add_recipe(rec) %>%
  add_model(rf_model)

xgb_workflow <- workflow() %>%
  add_recipe(rec) %>%
  add_model(xgb_model)

dt_workflow <- workflow() %>%
  add_recipe(rec) %>%
  add_model(dt_model)

model_set <- workflow_set(
  preproc = list(recipe = rec),
  models = list(rf = rf_model, xgb = xgb_model, dt = dt_model)
)

set.seed(123)
cv_folds <- vfold_cv(camels_train, v = 10)

model_results <- model_set %>%
  workflow_map(
    "fit_resamples",
    resamples = cv_folds,
    metrics = metric_set(rmse, rsq)
  )

model_results %>% autoplot()
```

#4e. Evaluation

```{r}
autoplot(model_results)
rank_results(model_results, rank_metric = "rmse", select_best = TRUE)

#I think the best model is the XGBoost because it has the highest R^2 so it would explain the most variance in the logQmean
```

#4f. Extract and Evaluate

```{r}
camels_recipe <- recipe(logQmean ~ p_mean + pet_mean + elev_mean + area_gages2 + soil_porosity + slope_mean, 
                        data = camels_train) %>%
  step_normalize(all_predictors())

xgb_workflow <- workflow() %>%
  add_model(xgb_model) %>%
  add_recipe(rec)

xgb_fit <- fit(xgb_workflow, data = camels_train)

camels_recipe <- recipe(logQmean ~ p_mean + pet_mean + elev_mean + area_gages2 + soil_porosity + slope_mean, 
                        data = camels_train) %>%
  step_impute_median(all_numeric_predictors()) %>%
  step_normalize(all_predictors()) 

camels_train <- camels_train %>% drop_na(logQmean)

xgb_workflow <- workflow() %>%
  add_model(xgb_model) %>%
  add_recipe(camels_recipe)

xgb_fit <- fit(xgb_workflow, data = camels_train)

test_predictions <- predict(xgb_fit, new_data = camels_test) %>%
  bind_cols(camels_test)


ggplot(test_predictions, aes(x = .pred, y = logQmean)) +
  geom_point(alpha = 0.6, color = "blue") +  
  geom_abline(slope = 1, intercept = 0, linetype = "dashed", color = "red") +  
  labs(
    title = "Observed vs. Predicted logQmean",
    x = "Predicted logQmean",
    y = "Observed logQmean"
  ) +
  theme_minimal()

#The resulted plot has a strong positive correlation which means that it is likely that the model is making fairly accurate predictions. The model struggles with the lower values as they have more spread than the higher ones.
```
